{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standart Python notebook imports\n",
    "\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as sopt\n",
    "import scipy.stats as sstats\n",
    "import seaborn as sns\n",
    "import sklearn.ensemble\n",
    "import sklearn.tree\n",
    "from sklearn import datasets\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import animation, pyplot, rc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output types are onedim nparrays\n",
    "\n",
    "\n",
    "import string\n",
    "characters = string.printable\n",
    "\n",
    "def stats(x):\n",
    "    return np.array([x.min(), x.max(), x.mean(), x.std()])\n",
    "\n",
    "def to_str(seq):\n",
    "    return np.array(list(map(str, seq)))\n",
    "\n",
    "def length(seq):\n",
    "    res = list(map(len, seq))\n",
    "    return stats(np.array(res))\n",
    "\n",
    "def numeric_percent(seq):\n",
    "    res = list(map(lambda s: sum([c.isnumeric() for c in s]) / len(s), seq))\n",
    "    return stats(np.array(res))\n",
    "\n",
    "def alphabet_percent(seq):\n",
    "    res = list(map(lambda s: sum([c.isalpha() for c in s]) / len(s), seq))\n",
    "    return stats(np.array(res))\n",
    "    \n",
    "#def characters_percent(seq):\n",
    "#    for c in characters:\n",
    "    \n",
    "def features(seq):\n",
    "    detectors = [\n",
    "        length,\n",
    "   #     numeric_percent,\n",
    "   #     alphabet_percent,\n",
    "    ]\n",
    "    \n",
    "    features = np.array([])\n",
    "    for detector in detectors:\n",
    "        features = np.append(detector(to_str(seq)), features)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers\n",
    "\n",
    "\n",
    "raw = pd.read_csv(\"data/data0.csv\")\n",
    "raw.fillna(\"\");\n",
    "\n",
    "data = np.vstack(raw.columns.map(lambda c: features(raw[c].to_numpy().T.reshape(-1))).to_numpy())\n",
    "labels =  np.array([s[:(s+\".\").find('.')] for s in raw.columns.to_numpy()]) \n",
    "\n",
    "data, np.array([s[:(s+\".\").find('.')] for s in labels])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.00000000e+00, 5.00000000e+00, 3.48768864e+00, 1.38886963e+00],\n",
       "        [1.00000000e+00, 1.10000000e+01, 2.00953137e+00, 2.73077980e-01],\n",
       "        [2.00000000e+00, 1.00000000e+01, 4.97140588e+00, 3.50569384e+00],\n",
       "        [2.00000000e+00, 3.00000000e+00, 2.40905481e+00, 4.91659406e-01],\n",
       "        [1.00000000e+00, 4.60000000e+01, 3.99285147e+00, 2.22751507e+00],\n",
       "        [1.90000000e+01, 1.90000000e+01, 1.90000000e+01, 0.00000000e+00],\n",
       "        [2.00000000e+00, 1.00000000e+01, 3.37648928e+00, 2.80070683e+00],\n",
       "        [3.00000000e+00, 1.40000000e+01, 7.18030183e+00, 3.91815305e+00],\n",
       "        [9.00000000e+00, 1.80000000e+01, 1.15822081e+01, 2.68556602e+00],\n",
       "        [5.00000000e+00, 2.20000000e+01, 1.17132645e+01, 2.75984604e+00],\n",
       "        [2.00000000e+00, 3.00000000e+00, 2.39078634e+00, 4.87926609e-01],\n",
       "        [2.00000000e+00, 3.00000000e+00, 2.50595711e+00, 4.99964512e-01],\n",
       "        [3.00000000e+00, 9.00000000e+00, 6.19539317e+00, 2.33594920e+00],\n",
       "        [1.00000000e+00, 3.54800000e+03, 3.42859412e+01, 1.44188758e+02],\n",
       "        [2.00000000e+00, 1.00000000e+01, 5.93248610e+00, 3.75344812e+00],\n",
       "        [2.00000000e+00, 1.20000000e+01, 8.32644956e+00, 4.65103345e+00],\n",
       "        [2.00000000e+00, 1.00000000e+01, 7.50198570e+00, 3.41453523e+00],\n",
       "        [2.00000000e+00, 3.00000000e+00, 2.29864972e+00, 4.57665889e-01],\n",
       "        [2.00000000e+00, 1.20000000e+01, 5.18983320e+00, 4.24672278e+00],\n",
       "        [2.00000000e+00, 3.00000000e+00, 2.14614774e+00, 3.53254265e-01],\n",
       "        [2.00000000e+00, 5.00000000e+00, 2.52819698e+00, 1.11162141e+00]]),\n",
       " array(['phys_health_interview', 'age', 'benefits', 'state', 'gender',\n",
       "        'date', 'wellness_program', 'no_employees', 'leave', 'country',\n",
       "        'boolean', 'boolean', 'work_interfere', 'comments',\n",
       "        'mental_vs_physical', 'coworkers', 'anonymity', 'remote_work',\n",
       "        'supervisor', 'obs_consequence', 'mental_health_interview'],\n",
       "       dtype='<U25'))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
